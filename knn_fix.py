# -*- coding: utf-8 -*-
"""KNN Fix.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JrSACjurFCUu6NmKlCEm2brlvwBjrHj2

**<h1 style="font-size:36px;"> Klasifikasi Data Stunting Kabupaten Pemalang Dengan K-Nearest Neighbor - Rangga Aditya Nugraha</h1>**
"""

# ===========================================================================================================================
# ==================================================== Import Library =======================================================
# ===========================================================================================================================

import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from google.colab import drive
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.metrics import roc_curve, auc
import warnings
warnings.filterwarnings('ignore')

# ===========================================================================================================================
# ==================================================== Mount Google Drive ===================================================
# ===========================================================================================================================

drive.mount('/content/drive')

# ===========================================================================================================================
# ====================================================== Load Data ==========================================================
# ===========================================================================================================================

file_path = '/content/drive/MyDrive/Proposal TA/DATASET/data_stunting.xlsx'
df = pd.read_excel(file_path)

"""# **1Ô∏è‚É£ Data Cleaning**"""

# ===========================================================================================================================
# ============================================== Cek Ukuran Data ============================================================
# # =========================================================================================================================

print("\nUkuran Data:", df.shape)

print("\nInfo Dataset:")
print(df.info())

print("\nPreview Data:")
print(df.head())

# ===========================================================================================================================
# =============================================== Hapus Kolom Tidak Digunakan ===============================================
# ===========================================================================================================================

kolom_dihapus = [
    'No', 'Tgl Lahir', 'Prov', 'Kab/Kota', 'Kec',
    'Pukesmas', 'Desa/Kel', 'Posyandu', 'RT', 'RW', 'Alamat', 'Tanggal Pengukuran', 'Cara Ukur', 'Naik Berat Badan'
]

df = df.drop(columns=kolom_dihapus, errors='ignore')

print("\nData Setelah Kolom Tertentu Dihapus:")
print(df.head())

# ===========================================================================================================================
# =================================================== Rename Nama Kolom =====================================================
# ===========================================================================================================================

df = df.rename(columns={
    'JK': 'Gender',
    'BB Lahir': 'Birth Weight',
    'TB Lahir': 'Birth Height',
    'Usia Saat Ukur': 'Age at Measurement',
    'Berat': 'Weight',
    'Tinggi': 'Height',
})

print(df.head())

# ===========================================================================================================================
# =================================================== Rename Column Values ==================================================
# ===========================================================================================================================

df['BB/U'] = df['BB/U'].replace({
    'Kurang': 'Underweight',
    'Normal': 'Normal',
    'Risiko Lebih': 'At Risk of Overweight',
    'Sangat Kurang': 'Severely Underweight'
})

df['TB/U'] = df['TB/U'].replace({
    'Normal': 'Normal',
    'Pendek': 'Short',
    'Sangat Pendek': 'Very Short',
    'Tinggi': 'Tall'
})

df['BB/TB'] = df['BB/TB'].replace({
    'Gizi Baik': 'Good Nutrition',
    'Gizi Buruk': 'Severe Malnutrition',
    'Gizi Kurang': 'Poor Nutrition',
    'Gizi Lebih': 'Overnutrition',
    'Obesitas': 'Obesity',
    'Risiko Gizi Lebih': 'At Risk of Overnutrition'
})

df['Gender'] = df['Gender'].replace({'L': 'Male', 'P': 'Female'})
print(df.head())

# ===========================================================================================================================
# ================================================= Konversi Usia ke Hari ===================================================
# ===========================================================================================================================

def usia_ke_hari(usia_str):
    match = re.findall(r'(\d+)\s*Tahun|\d+\s*Bulan|\d+\s*Hari', usia_str)
    angka = list(map(int, re.findall(r'\d+', usia_str)))
    tahun = angka[0] if len(angka) > 0 else 0
    bulan = angka[1] if len(angka) > 1 else 0
    hari = angka[2] if len(angka) > 2 else 0
    total_hari = tahun * 365 + bulan * 30 + hari
    return total_hari

df['Age'] = df['Age at Measurement'].apply(usia_ke_hari)
print(df[['Age at Measurement', 'Age']].head())

# ===========================================================================================================================
# ============================================= Hapus Kolom Sebelum Konversi ================================================
# ===========================================================================================================================

df.drop(columns=['Age at Measurement'], inplace=True)

# ===========================================================================================================================
# ========================================== Mengubah Tipe Data Pada Kolom Numerik ==========================================
# ===========================================================================================================================

numerical_cols = ['Birth Weight', 'Birth Height', 'Age', 'Weight', 'Height', 'ZS BB/U', 'ZS TB/U', 'ZS BB/TB']
df[numerical_cols] = df[numerical_cols].apply(pd.to_numeric, errors='coerce')

# ===========================================================================================================================
# ============================== Konversi Kolom Kategorikal atau Ordinal Sesuai Kebutuhan ===================================
# ===========================================================================================================================

categorical_cols = [
    'Gender', 'BB/U','TB/U', 'BB/TB'
]
df[categorical_cols] = df[categorical_cols].astype(str)

# ===========================================================================================================================
# ================================================== Info Dataset (Update) ==================================================
# ===========================================================================================================================

print(df.info())

# ===========================================================================================================================
# ================================================ Cek Missing Values =======================================================
# ===========================================================================================================================

df.isnull().sum()

# ===========================================================================================================================
# ============================================ Hapus Missing Values =========================================================
# ===========================================================================================================================

df_result = df.dropna(subset=['ZS BB/U', 'ZS TB/U', 'ZS BB/TB', 'BB/U', 'TB/U', 'BB/TB'])

# ===========================================================================================================================
# ================================================= Update Dataframe ========================================================
# ===========================================================================================================================

df=df_result

# ===========================================================================================================================
# ================================================ Cek Missing Values =======================================================
# ===========================================================================================================================

df.isnull().sum()

# ===========================================================================================================================
# =================================================== Cek Duplikat ==========================================================
# ===========================================================================================================================

df.duplicated().sum()

# ===========================================================================================================================
# ========================================== Hapus Baris Duplikat di Semua Kolom ============================================
# ===========================================================================================================================

df = df.drop_duplicates()

# ===========================================================================================================================
# =================================================== Cek Duplikat ==========================================================
# ===========================================================================================================================

df.duplicated().sum()

# ===========================================================================================================================
# ==================================== Cek Garbage Value Pada Data Tipe Object ==============================================
# ===========================================================================================================================

for i in df.select_dtypes(include="object").columns:
  print(df[i].value_counts())
  print("***"*10)

# ===========================================================================================================================
# ========================================= Deteksi Garbage Values pada Kategori ============================================
# ===========================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------
# Cek nilai yang seharusnya kategori, tapi malah berupa angka (meskipun dalam bentuk string)
# ---------------------------------------------------------------------------------------------------------------------------
for col in df.select_dtypes(include="object").columns:
    print(f"Garbage values in column '{col}':")
    garbage_values = df[col].unique()
    for val in garbage_values:
        try:
            float(val)
            print(f"  - {val}")
        except:
            continue
    print("***" * 10)

# ===========================================================================================================================
# ========================================= Hapus Garbage Values pada Kategori ==============================================
# ===========================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------
# Fungsi bantu untuk deteksi angka
# ---------------------------------------------------------------------------------------------------------------------------
def is_number(x):
    try:
        float(x)
        return True
    except:
        return False

# ---------------------------------------------------------------------------------------------------------------------------
# Hapus garbage value
# ---------------------------------------------------------------------------------------------------------------------------
for col in df.select_dtypes(include="object").columns:
    df[col] = df[col].apply(lambda x: x if not is_number(x) else None)

# ===========================================================================================================================
# ========================= Cek Garbage Value Pada Data Tipe Object (Seharusnya Sudah Hilang) ===============================
# ===========================================================================================================================

for i in df.select_dtypes(include="object").columns:
  print(df[i].value_counts())
  print("***"*10)

# ===========================================================================================================================
# =================================== Handle Outliers dengan IQR (Winsorization) ============================================
# ===========================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------
# Handle outliers menggunakan IQR method dengan winsorization untuk mempertahankan data sebanyak mungkin
# Method ini mengganti nilai ekstrem dengan batas IQR instead of menghapus data
# ---------------------------------------------------------------------------------------------------------------------------

def handle_outliers_iqr(df, columns):
    df_clean = df.copy()

    for col in columns:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # -------------------------------------------------------------------------------------------------------------------
        # Winsorization: ganti outlier dengan nilai batas
        # -------------------------------------------------------------------------------------------------------------------
        df_clean[col] = np.clip(df_clean[col], lower_bound, upper_bound)

    return df_clean

# ---------------------------------------------------------------------------------------------------------------------------
# Apply outlier handling pada kolom numerik
# ---------------------------------------------------------------------------------------------------------------------------
outlier_cols = ['Weight', 'Height', 'Birth Weight', 'Birth Height', 'ZS BB/U', 'ZS TB/U', 'ZS BB/TB']
df = handle_outliers_iqr(df, outlier_cols)

print(f"Outliers handled using IQR winsorization for {len(outlier_cols)} columns")

# ===========================================================================================================================
# ============================================== Cek Ukuran Data (Update) ===================================================
# ===========================================================================================================================

df.shape

"""# **2Ô∏è‚É£ Data Visualization**"""

# ===========================================================================================================================
# ================================================ Histogram Visualization ==================================================
# ===========================================================================================================================

purple_color = "#4B0082"

for col in numerical_cols:
    sns.histplot(data=df, x=col, color=purple_color, kde=True)
    plt.title(f"Histogram of {col}")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.grid(alpha=0.2)
    plt.show()

# ===========================================================================================================================
# ======================================================= Boxplot ===========================================================
# ===========================================================================================================================

purple_color = "#4B0082"
for col in numerical_cols:
    sns.boxplot(data=df, x=col, color=purple_color)
    plt.title(f"Boxplot of {col}")
    plt.xlabel(col)
    plt.grid(alpha=0.2)
    plt.show()

# ===========================================================================================================================
# ================================================== Scatter Plot ===========================================================
# ===========================================================================================================================

features = ['Birth Weight', 'Birth Height', 'Weight', 'Height', 'Age']
target_columns = ['ZS BB/U', 'ZS TB/U', 'ZS BB/TB']

purple_color = "#4B0082"

for target in target_columns:
    for feature in features:
        sns.scatterplot(
            data=df,
            x=feature,
            y=target,
            color=purple_color,
            alpha=0.7,
            edgecolor="none"
        )
        plt.title(f'{target} vs {feature}', fontsize=12)
        plt.xlabel(feature)
        plt.ylabel(target)
        plt.grid(alpha=0.2)
        plt.show()

# ===========================================================================================================================
# =========================================== Korelasi Dengan Heatmap =======================================================
# ===========================================================================================================================

s=df.select_dtypes(include="number").corr()

# ===========================================================================================================================
# =================================================== Korelasi Dengan Heatmap ===============================================
# ===========================================================================================================================

plt.figure(figsize=(15, 15))
sns.heatmap(s, annot=True, cmap='Purples')
plt.show()

# ===========================================================================================================================
# ========================================================= Pairplot ========================================================
# ===========================================================================================================================

sns.pairplot(df[numerical_cols], diag_kind='kde', palette="Reds")
plt.suptitle("Pairplot - Hubungan antar Variabel Numerik", y=1.02)
plt.show()

"""# **3Ô∏è‚É£ Data Transformation**"""

# ===========================================================================================================================
# ================================================ Statistik Deskriptif =====================================================
# ===========================================================================================================================

df.describe().T

# ===========================================================================================================================
# ================================= Statistik Deskriptif untuk Kolom Kategorikal ============================================
# ===========================================================================================================================

df.describe(include="object")

# ===========================================================================================================================
# =============================================== Statistik Z-Score =========================================================
# ===========================================================================================================================

print(f"Statistik Z-Score:")
zscore_cols = ['ZS BB/U', 'ZS TB/U', 'ZS BB/TB']
for col in zscore_cols:
    mean_val = df[col].mean()
    std_val = df[col].std()
    min_val = df[col].min()
    max_val = df[col].max()
    print(f"   {col}: Mean={mean_val:.2f} (¬±{std_val:.2f}), Range=[{min_val:.2f}, {max_val:.2f}]")

# ===========================================================================================================================
# =============================================== Statistik Antropometri ====================================================
# ===========================================================================================================================

print(f"Statistik Antropometri:")
anthro_cols = ['Birth Weight', 'Birth Height', 'Weight', 'Height']
for col in anthro_cols:
    mean_val = df[col].mean()
    std_val = df[col].std()
    min_val = df[col].min()
    max_val = df[col].max()
    print(f"   {col}: Mean={mean_val:.2f} (¬±{std_val:.2f}), Range=[{min_val:.2f}, {max_val:.2f}]")

# ===========================================================================================================================
# ===================================== Analisis Karakteristik Data Stunting ================================================
# ===========================================================================================================================

print("ANALISIS KARAKTERISTIK DATA STUNTING")

# ---------------------------------------------------------------------------------------------------------------------------
# Informasi umum dataset
# ---------------------------------------------------------------------------------------------------------------------------
print(f"Total sampel: {df.shape[0]:,} anak")
print(f"Total fitur: {df.shape[1]} variabel")
print(f"Rentang usia: {df['Age'].min()} - {df['Age'].max()} hari")
print(f"Rentang usia: {df['Age'].min()//365:.1f} - {df['Age'].max()//365:.1f} tahun")

# ---------------------------------------------------------------------------------------------------------------------------
# Distribusi jenis kelamin
# ---------------------------------------------------------------------------------------------------------------------------
print(f"\nDistribusi Jenis Kelamin:")
gender_dist = df['Gender'].value_counts()
for gender, count in gender_dist.items():
    print(f"   {gender}: {count:,} ({count/len(df)*100:.1f}%)")

# ===========================================================================================================================
# =========================================== Buat Target Binary Stunting ===================================================
# ===========================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------
# Membuat target binary stunting berdasarkan kolom TB/U yang sudah ada
# Kategori 'Pendek' dan 'Sangat Pendek' = Stunting (1), sisanya = Normal (0)
# ---------------------------------------------------------------------------------------------------------------------------

df['stunting'] = df['TB/U'].apply(lambda x: 1 if str(x).lower() in ['short', 'very short'] else 0)

# ---------------------------------------------------------------------------------------------------------------------------
# Analisis distribusi target
# ---------------------------------------------------------------------------------------------------------------------------
stunting_counts = df['stunting'].value_counts()
total_samples = len(df)

print(f"Distribusi Target (Stunting):")
print(f"Tidak Stunting (0): {stunting_counts[0]:,} ({stunting_counts[0]/total_samples*100:.1f}%)")
print(f"Stunting (1): {stunting_counts[1]:,} ({stunting_counts[1]/total_samples*100:.1f}%)")

# ---------------------------------------------------------------------------------------------------------------------------
# Menghitung rasio imbalance
# ---------------------------------------------------------------------------------------------------------------------------
imbalance_ratio = stunting_counts[0] / stunting_counts[1]
print(f"Rasio Imbalance: {imbalance_ratio:.2f}:1")

"""# **4Ô∏è‚É£ Data Reduction**"""

# ===========================================================================================================================
# =============================================== Persiapan Fitur dan Target ================================================
# ===========================================================================================================================

numerical_features = [
    'Birth Weight', 'Birth Height', 'Weight', 'Height', 'Age'
]

# ---------------------------------------------------------------------------------------------------------------------------
# Fitur kategorikal
# ---------------------------------------------------------------------------------------------------------------------------
categorical_features = ['Gender']

# ---------------------------------------------------------------------------------------------------------------------------
# Encoding fitur kategorikal
# ---------------------------------------------------------------------------------------------------------------------------
df_encoded = df.copy()
le = LabelEncoder()
df_encoded['Gender_encoded'] = le.fit_transform(df_encoded['Gender'])

# ---------------------------------------------------------------------------------------------------------------------------
# Gabungkan semua fitur
# ---------------------------------------------------------------------------------------------------------------------------
all_features = numerical_features + ['Gender_encoded']

# ---------------------------------------------------------------------------------------------------------------------------
# Persiapkan x dan y
# ---------------------------------------------------------------------------------------------------------------------------
x = df_encoded[all_features]
y = df_encoded['stunting']

print(f"Fitur yang digunakan ({len(all_features)}):")
for i, feature in enumerate(all_features, 1):
    print(f"   {i}. {feature}")

print(f"\nTarget: stunting (0=Tidak Stunting, 1=Stunting)")
print(f"Bentuk data: x={x.shape}, y={y.shape}")

# ---------------------------------------------------------------------------------------------------------------------------
# Tampilkan mapping hasil Gender_encoded
# ---------------------------------------------------------------------------------------------------------------------------
print("\nMapping Gender -> Gender_encoded:")
print(df_encoded[['Gender', 'Gender_encoded']].drop_duplicates())

# ===========================================================================================================================
# ================================================ FEATURE SELECTION ========================================================
# ===========================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------
# Hitung korelasi fitur dengan target stunting
# ---------------------------------------------------------------------------------------------------------------------------
correlation_with_target = pd.concat([x, y], axis=1).corr()['stunting'].drop('stunting').sort_values(key=abs, ascending=False)
print("\nüîé Korelasi antara fitur dan target (stunting):")
print(correlation_with_target)

# ---------------------------------------------------------------------------------------------------------------------------
# Seleksi fitur berdasarkan threshold korelasi
# ---------------------------------------------------------------------------------------------------------------------------
threshold = 0.1
selected_features = correlation_with_target[abs(correlation_with_target) >= threshold].index.tolist()

# ---------------------------------------------------------------------------------------------------------------------------
# Jika tidak ada fitur yang memenuhi threshold ‚Üí pakai semua fitur numerik saja
# ---------------------------------------------------------------------------------------------------------------------------
if len(selected_features) == 0:
    print(f"\n‚ö†Ô∏è Tidak ada fitur dengan korelasi ‚â• {threshold}. Semua fitur numerik akan digunakan untuk PCA.")
    selected_features = x.select_dtypes(include=[np.number]).columns.tolist()
else:
    print(f"\n‚úÖ Fitur yang dipilih berdasarkan korelasi ‚â• {threshold}:")
    for f in selected_features:
        print(f"   - {f}")

# ---------------------------------------------------------------------------------------------------------------------------
# Pastikan hanya kolom numerik yang digunakan
# ---------------------------------------------------------------------------------------------------------------------------
x_selected = x[selected_features].select_dtypes(include=[np.number])

# ---------------------------------------------------------------------------------------------------------------------------
# Validasi hasil
# ---------------------------------------------------------------------------------------------------------------------------
if x_selected.shape[1] == 0:
    raise ValueError("‚ùå Tidak ada kolom numerik yang tersedia untuk PCA. Periksa kembali tipe data fitur.")

print(f"\nBentuk data setelah Feature Selection: {x_selected.shape}")
print(f"Tipe data fitur terpilih:\n{x_selected.dtypes}")

# ===========================================================================================================================
# ================================================ Split Data Training/Testing ==============================================
# ===========================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------
# Membagi data menjadi training set dan testing set
# ---------------------------------------------------------------------------------------------------------------------------
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=42, stratify=y
)

# ---------------------------------------------------------------------------------------------------------------------------
# Menampilkan jumlah sampel
# ---------------------------------------------------------------------------------------------------------------------------
print(f"Data Training: {x_train.shape[0]:,} sampel")
print(f"Data Testing: {x_test.shape[0]:,} sampel")


# ===========================================================================================================================
# ======================================== Distribusi Kelas pada Training & Testing =========================================
# ===========================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------
# Distribusi kelas di training set
# ---------------------------------------------------------------------------------------------------------------------------
train_dist = Counter(y_train)
print(f"\nDistribusi Training Set:")
print(f"   Tidak Stunting: {train_dist[0]:,} ({train_dist[0]/len(y_train)*100:.1f}%)")
print(f"   Stunting: {train_dist[1]:,} ({train_dist[1]/len(y_train)*100:.1f}%)")

# ---------------------------------------------------------------------------------------------------------------------------
# Distribusi kelas di testing set
# ---------------------------------------------------------------------------------------------------------------------------
test_dist = Counter(y_test)
print(f"\nDistribusi Testing Set:")
print(f"   Tidak Stunting: {test_dist[0]:,} ({test_dist[0]/len(y_test)*100:.1f}%)")
print(f"   Stunting: {test_dist[1]:,} ({test_dist[1]/len(y_test)*100:.1f}%)")

"""# **5Ô∏è‚É£ SMOTE**"""

# ===========================================================================================================================
# ========================================================== SMOTE ==========================================================
# ===========================================================================================================================

from imblearn.over_sampling import SMOTE
from collections import Counter
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer

# ---------------------------------------------------------------------------------------------------------------------------
# Cek Missing Values di Training Set
# ---------------------------------------------------------------------------------------------------------------------------
print("üìå Cek missing values di x_train:")
print(x_train.isnull().sum())

# ---------------------------------------------------------------------------------------------------------------------------
# Handle Missing Values
# Mengisi NaN dengan median kolom
# ---------------------------------------------------------------------------------------------------------------------------
imputer = SimpleImputer(strategy='median')
x_train_imputed = pd.DataFrame(imputer.fit_transform(x_train), columns=x_train.columns)
x_test_imputed = pd.DataFrame(imputer.transform(x_test), columns=x_test.columns)  # agar konsisten

# ---------------------------------------------------------------------------------------------------------------------------
# Distribusi Sebelum SMOTE
# ---------------------------------------------------------------------------------------------------------------------------
class_distribution_before = Counter(y_train)
print("\nüìä DISTRIBUSI KELAS SEBELUM SMOTE (Training Set):")
print(f"   Tidak Stunting: {class_distribution_before[0]:,} ({class_distribution_before[0]/len(y_train)*100:.1f}%)")
print(f"   Stunting: {class_distribution_before[1]:,} ({class_distribution_before[1]/len(y_train)*100:.1f}%)")

imbalance_ratio = max(class_distribution_before.values()) / min(class_distribution_before.values())
print(f"\nüìà Rasio imbalance: {imbalance_ratio:.2f}")

# ---------------------------------------------------------------------------------------------------------------------------
# Terapkan SMOTE jika Imbalanced
# ---------------------------------------------------------------------------------------------------------------------------
if imbalance_ratio > 1.5:
    smote = SMOTE(
        sampling_strategy='auto',
        random_state=42,
        k_neighbors=min(5, min(class_distribution_before.values()) - 1) if min(class_distribution_before.values()) > 1 else 1
    )

    x_train_res, y_train_res = smote.fit_resample(x_train_imputed, y_train)
    x_test_res, y_test_res = x_test_imputed.copy(), y_test.copy()

    print("\n‚úÖ SMOTE diterapkan pada data training!")
else:
    print("\n‚úÖ Dataset sudah seimbang, SMOTE tidak diterapkan.")
    x_train_res, y_train_res = x_train_imputed.copy(), y_train.copy()
    x_test_res, y_test_res = x_test_imputed.copy(), y_test.copy()

# ---------------------------------------------------------------------------------------------------------------------------
# Visualisasi Sebelum & Sesudah
# ---------------------------------------------------------------------------------------------------------------------------
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# ---------------------------------------------------------------------------------------------------------------------------
# Sebelum SMOTE
# ---------------------------------------------------------------------------------------------------------------------------
axes[0].bar(["Not Stunted", "Stunted"], class_distribution_before.values(), color='#BDEBBF')
axes[0].set_title('Distribution Class Before SMOTE')
axes[0].set_ylabel('Total Sample')
for i, v in enumerate(class_distribution_before.values()):
    axes[0].text(i, v + 50, f"{v:,}", ha='center')

# ---------------------------------------------------------------------------------------------------------------------------
# Sesudah SMOTE
# ---------------------------------------------------------------------------------------------------------------------------
class_distribution_after = Counter(y_train_res)
axes[1].bar(["Not Stunted", "Stunted"], class_distribution_after.values(), color='#20B03F')
axes[1].set_title('Distribution Class After SMOTE')
axes[1].set_ylabel('Total Sample')
for i, v in enumerate(class_distribution_after.values()):
    axes[1].text(i, v + 50, f"{v:,}", ha='center')

plt.tight_layout()
plt.show()

# ---------------------------------------------------------------------------------------------------------------------------
# Preview Data Hasil SMOTE
# ---------------------------------------------------------------------------------------------------------------------------
df_smote = pd.DataFrame(x_train_res, columns=x_train.columns)
df_smote['stunting'] = y_train_res
print("\nüìÑ Preview Data Hasil SMOTE:")
print(df_smote.head(10))
print("\nüî¢ Jumlah sampel per kelas setelah SMOTE:")
print(df_smote['stunting'].value_counts())

# ===========================================================================================================================
# ================================= Scaling / Standardization Setelah SMOTE =================================================
# ===========================================================================================================================

from sklearn.preprocessing import StandardScaler

# ---------------------------------------------------------------------------------------------------------------------------
# Pilih kolom numerik yang ingin di-scale
# ---------------------------------------------------------------------------------------------------------------------------
numerical_features = ['Birth Weight', 'Birth Height', 'Weight', 'Height', 'Age']

# ---------------------------------------------------------------------------------------------------------------------------
# Inisialisasi scaler
# ---------------------------------------------------------------------------------------------------------------------------
scaler = StandardScaler()

# ---------------------------------------------------------------------------------------------------------------------------
# Terapkan scaling hanya pada data training hasil SMOTE
# ---------------------------------------------------------------------------------------------------------------------------
x_train_res_scaled = x_train_res.copy()
x_train_res_scaled[numerical_features] = scaler.fit_transform(x_train_res[numerical_features])

# ---------------------------------------------------------------------------------------------------------------------------
# Scaling pada data testing (gunakan scaler yang sama)
# ---------------------------------------------------------------------------------------------------------------------------
x_test_res_scaled = x_test_res.copy()
x_test_res_scaled[numerical_features] = scaler.transform(x_test_res[numerical_features])

# ---------------------------------------------------------------------------------------------------------------------------
# Buat DataFrame hasil scaling (opsional, untuk dicek)
# ---------------------------------------------------------------------------------------------------------------------------
df_train_scaled = pd.DataFrame(x_train_res_scaled, columns=x_train_res_scaled.columns)
df_train_scaled['stunting'] = y_train_res

# ---------------------------------------------------------------------------------------------------------------------------
# Preview data
# ---------------------------------------------------------------------------------------------------------------------------
print("\nüìÑ Preview Data Training Hasil SMOTE + Scaling:")
print(df_train_scaled.head())

# ---------------------------------------------------------------------------------------------------------------------------
# Statistik setelah scaling
# ---------------------------------------------------------------------------------------------------------------------------
print("\nüìä Statistik numerik setelah scaling:")
print(df_train_scaled[numerical_features].describe().T)

# ---------------------------------------------------------------------------------------------------------------------------
# Visualisasi distribusi setelah scaling (opsional)
# ---------------------------------------------------------------------------------------------------------------------------
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))
sns.boxplot(data=df_train_scaled[numerical_features], palette="Blues")
plt.title("Distribusi Data Training Setelah SMOTE + Scaling (Z-score)")
plt.xticks(rotation=45)
plt.grid(alpha=0.2)
plt.show()

# ==========================================================
# üîπ SCALING DATA TANPA SMOTE
# ==========================================================
from sklearn.preprocessing import StandardScaler

scaler_no_smote = StandardScaler()
x_train_imputed_scaled = scaler_no_smote.fit_transform(x_train_imputed)
x_test_imputed_scaled = scaler_no_smote.transform(x_test_imputed)

print("\nüìä Data Training dan Testing TANPA SMOTE telah di-scale!")
print("x_train_imputed_scaled shape:", x_train_imputed_scaled.shape)
print("x_test_imputed_scaled shape:", x_test_imputed_scaled.shape)

"""# **6Ô∏è‚É£K-Nearest Neighbor**"""

# ==========================================================
# KNN TANPA SMOTE
# ==========================================================

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Gunakan data sebelum SMOTE & sebelum scaling (x_train_imputed, x_test_imputed)
# Jika ingin scaling tetap konsisten, gunakan x_train_imputed_scaled dan x_test_imputed_scaled
# (karena kamu sudah buat scaler sebelumnya)

# Latih model KNN
knn_no_smote = KNeighborsClassifier(n_neighbors=5)
knn_no_smote.fit(x_train_imputed_scaled, y_train)

# Prediksi pada data test
y_pred_no_smote = knn_no_smote.predict(x_test_imputed_scaled)

# Evaluasi hasil
print("üìä HASIL KNN TANPA SMOTE")
print("Akurasi:", accuracy_score(y_test, y_pred_no_smote))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_no_smote, target_names=['Tidak Stunting', 'Stunting']))

# Confusion Matrix
cm_no_smote = confusion_matrix(y_test, y_pred_no_smote)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_no_smote, annot=True, fmt="d", cmap="Blues", xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])
plt.title("Confusion Matrix ‚Äî KNN tanpa SMOTE")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.show()

# ==========================================================
# KNN DENGAN SMOTE + STANDARDIZATION
# ==========================================================

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Gunakan data hasil SMOTE + scaling (x_train_res_scaled, x_test_res_scaled)

# Latih model KNN
knn_smote = KNeighborsClassifier(n_neighbors=5)
knn_smote.fit(x_train_res_scaled, y_train_res)

# Prediksi pada data test
y_pred_smote = knn_smote.predict(x_test_res_scaled)

# Evaluasi hasil
print("üìä HASIL KNN DENGAN SMOTE + SCALING")
print("Akurasi:", accuracy_score(y_test_res, y_pred_smote))
print("\nClassification Report:")
print(classification_report(y_test_res, y_pred_smote, target_names=['Tidak Stunting', 'Stunting']))

# Confusion Matrix
cm_smote = confusion_matrix(y_test_res, y_pred_smote)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_smote, annot=True, fmt="d", cmap="Purples", xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])
plt.title("Confusion Matrix ‚Äî KNN dengan SMOTE + Scaling")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.show()

# ==========================================================
# üüß BLOK ‚Äî PERBANDINGAN KINERJA MODEL KNN (TANPA vs DENGAN SMOTE)
# ==========================================================

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import matplotlib.pyplot as plt

# Hitung metrik untuk model TANPA SMOTE
metrics_no_smote = {
    "Accuracy": accuracy_score(y_test, y_pred_no_smote),
    "Precision": precision_score(y_test, y_pred_no_smote, zero_division=0),
    "Recall": recall_score(y_test, y_pred_no_smote, zero_division=0),
    "F1-Score": f1_score(y_test, y_pred_no_smote, zero_division=0)
}

# Hitung metrik untuk model DENGAN SMOTE
metrics_smote = {
    "Accuracy": accuracy_score(y_test_res, y_pred_smote),
    "Precision": precision_score(y_test_res, y_pred_smote, zero_division=0),
    "Recall": recall_score(y_test_res, y_pred_smote, zero_division=0),
    "F1-Score": f1_score(y_test_res, y_pred_smote, zero_division=0)
}

# Buat DataFrame perbandingan
df_compare = pd.DataFrame([metrics_no_smote, metrics_smote],
                          index=["Imbalanced", "With SMOTE"])

# Tampilkan tabel hasil
print("üìä PERBANDINGAN KINERJA MODEL KNN:")
display(df_compare)

# ==========================================================
# Visualisasi Perbandingan (Style seperti RF)
# ==========================================================
plt.figure(figsize=(8, 5))
df_compare.plot(kind="bar",
                color=["#A3D8F4", "#4B88A2", "#F9ED69", "#F08A5D"],
                figsize=(8, 5))
plt.title("Comparation Performance KNN Imbalanced vs With SMOTE", fontsize=13)
plt.ylabel("Nilai Metrik")
plt.ylim(0, 1)
plt.xticks(rotation=0)
plt.grid(axis="y", alpha=0.3)
plt.legend(title="Metrik")
plt.tight_layout()
plt.show()

# ==========================================================
# Hyperparameter Tuning KNN (CROSS-VALIDATION) Denagan SMOTE
# ==========================================================

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# ==========================================================
# Definisikan parameter grid
# ==========================================================
param_grid = {
    'n_neighbors': [3, 5, 7, 9, 11],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

# ==========================================================
# Inisialisasi model dasar
# ==========================================================
knn_tuned = KNeighborsClassifier()

# ==========================================================
# Lakukan GridSearchCV dengan 5-fold cross-validation
# ==========================================================
grid_search = GridSearchCV(
    estimator=knn_tuned,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

# Gunakan data hasil SMOTE + scaling
grid_search.fit(x_train_res_scaled, y_train_res)

# ==========================================================
# Tampilkan hasil terbaik
# ==========================================================
print("\n‚úÖ Hasil Hyperparameter Tuning:")
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}")

# ==========================================================
# Evaluasi model terbaik di data testing
# ==========================================================
best_knn = grid_search.best_estimator_
y_pred_best = best_knn.predict(x_test_res_scaled)

print("\nüìä Laporan Klasifikasi (Model Terbaik):")
print(classification_report(y_test_res, y_pred_best))

# ==========================================================
# Confusion Matrix
# ==========================================================
cm = confusion_matrix(y_test_res, y_pred_best)

plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', cbar=False)
plt.title("Confusion Matrix ‚Äî KNN (Best Model)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# ==========================================================
# Perbandingan Akurasi
# ==========================================================
acc_baseline = accuracy_score(y_test_res, y_pred_smote)
acc_tuned = accuracy_score(y_test_res, y_pred_best)

print(f"\nüìà Akurasi Model Baseline (KNN default): {acc_baseline:.4f}")
print(f"üèÜ Akurasi Model Setelah Tuning: {acc_tuned:.4f}")

# ==========================================================
# Hyperparameter Tuning KNN (CROSS-VALIDATION) Tanpa SMOTE
# ==========================================================

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# ==========================================================
# Definisikan parameter grid
# ==========================================================
param_grid_no_smote = {
    'n_neighbors': [3, 5, 7, 9, 11],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

# ==========================================================
# Inisialisasi model dasar
# ==========================================================
knn_tuned_no_smote = KNeighborsClassifier()

# ==========================================================
# Lakukan GridSearchCV dengan 5-fold cross-validation
# ==========================================================
grid_search_no_smote = GridSearchCV(
    estimator=knn_tuned_no_smote,
    param_grid=param_grid_no_smote,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

# Gunakan data sebelum SMOTE (yang sudah di-scale agar konsisten)
grid_search_no_smote.fit(x_train_imputed_scaled, y_train)

# ==========================================================
# Tampilkan hasil terbaik
# ==========================================================
print("\n‚úÖ Hasil Hyperparameter Tuning (Tanpa SMOTE):")
print(f"Best Parameters: {grid_search_no_smote.best_params_}")
print(f"Best Cross-Validation Accuracy: {grid_search_no_smote.best_score_:.4f}")

# ==========================================================
# Evaluasi model terbaik di data testing
# ==========================================================
best_knn_no_smote = grid_search_no_smote.best_estimator_
y_pred_best_no_smote = best_knn_no_smote.predict(x_test_imputed_scaled)

print("\nüìä Laporan Klasifikasi (Model Terbaik - Tanpa SMOTE):")
print(classification_report(y_test, y_pred_best_no_smote, target_names=['Tidak Stunting', 'Stunting']))

# ==========================================================
# Confusion Matrix
# ==========================================================
cm_no_smote_best = confusion_matrix(y_test, y_pred_best_no_smote)

plt.figure(figsize=(5, 4))
sns.heatmap(cm_no_smote_best, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title("Confusion Matrix ‚Äî KNN (Best Model, Tanpa SMOTE)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# ==========================================================
# Perbandingan Akurasi (Default vs Tuned)
# ==========================================================
acc_baseline_no_smote = accuracy_score(y_test, y_pred_no_smote)
acc_tuned_no_smote = accuracy_score(y_test, y_pred_best_no_smote)

print(f"\nüìà Akurasi Model Baseline (KNN default, tanpa SMOTE): {acc_baseline_no_smote:.4f}")
print(f"üèÜ Akurasi Model Setelah Tuning (tanpa SMOTE): {acc_tuned_no_smote:.4f}")

# ==========================================================
# Perbandingan Akurasi Train vs Test (KNN - Dengan SMOTE)
# ==========================================================

from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np

# Range nilai K
k_values = range(1, 51)
weights_options = ['uniform', 'distance']

plt.figure(figsize=(14, 4))

for i, w in enumerate(weights_options):
    train_acc = []
    test_acc = []

    for k in k_values:
        model = KNeighborsClassifier(n_neighbors=k, weights=w)
        model.fit(x_train_res_scaled, y_train_res)

        # Hitung akurasi
        train_acc.append(model.score(x_train_res_scaled, y_train_res))
        test_acc.append(model.score(x_test_res_scaled, y_test_res))

    # Subplot untuk setiap weight
    plt.subplot(1, 2, i+1)
    plt.plot(k_values, train_acc, 'o-', label='Train Accuracy')
    plt.plot(k_values, test_acc, 's--', label='Test Accuracy')
    plt.xlabel('n_neighbors (K)')
    plt.ylabel('Accuracy')
    plt.title(f"weights = '{w}'")
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.ylim(0.6, 1.05)

    # Titik terbaik (K dengan akurasi test tertinggi)
    best_k = np.argmax(test_acc) + 1
    best_test_acc = test_acc[best_k - 1]
    plt.axvline(best_k, color='gray', linestyle=':')
    plt.text(best_k, best_test_acc - 0.02,
             f"best K={best_k}\nTest={best_test_acc:.3f}",
             color='black', fontsize=9)

    plt.legend()

plt.suptitle("Perbandingan Akurasi Training vs Testing (Dengan SMOTE)")
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# ==========================================================
# Perbandingan Akurasi Train vs Test (KNN - Tanpa SMOTE)
# ==========================================================

from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np

# Range nilai K
k_values = range(1, 51)
weights_options = ['uniform', 'distance']

plt.figure(figsize=(14, 4))

for i, w in enumerate(weights_options):
    train_acc = []
    test_acc = []

    for k in k_values:
        model = KNeighborsClassifier(n_neighbors=k, weights=w)
        model.fit(x_train_imputed_scaled, y_train)

        # Hitung akurasi
        train_acc.append(model.score(x_train_imputed_scaled, y_train))
        test_acc.append(model.score(x_test_imputed_scaled, y_test))

    # Subplot untuk setiap weight
    plt.subplot(1, 2, i+1)
    plt.plot(k_values, train_acc, 'o-', label='Train Accuracy')
    plt.plot(k_values, test_acc, 's--', label='Test Accuracy')
    plt.xlabel('n_neighbors (K)')
    plt.ylabel('Accuracy')
    plt.title(f"weights = '{w}' (Tanpa SMOTE)")
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.ylim(0.6, 1.05)

    # Titik terbaik (K dengan akurasi test tertinggi)
    best_k = np.argmax(test_acc) + 1
    best_test_acc = test_acc[best_k - 1]
    plt.axvline(best_k, color='gray', linestyle=':')
    plt.text(best_k, best_test_acc - 0.02,
             f"best K={best_k}\nTest={best_test_acc:.3f}",
             color='black', fontsize=9)

    plt.legend()

plt.suptitle("Perbandingan Akurasi Training vs Testing (Tanpa SMOTE)")
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

"""# **ROC CURVE COMPARISON (KNN)**"""

# ==========================================================
# üìä KODE UNTUK MEMBUAT ROC CURVE COMPARISON (KNN)
# Letakkan di cell paling bawah
# ==========================================================

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# 1. Ambil Probabilitas dari Model KNN Terbaik (DENGAN SMOTE)
# Pastikan variabel 'best_knn' dan 'x_test_res_scaled' sudah ada dari cell sebelumnya
y_prob_smote = best_knn.predict_proba(x_test_res_scaled)[:, 1]

# 2. Ambil Probabilitas dari Model KNN Terbaik (TANPA SMOTE)
# Pastikan variabel 'best_knn_no_smote' dan 'x_test_imputed_scaled' sudah ada
y_prob_imbalanced = best_knn_no_smote.predict_proba(x_test_imputed_scaled)[:, 1]

# 3. Hitung FPR, TPR, dan AUC
fpr_smote, tpr_smote, _ = roc_curve(y_test_res, y_prob_smote)
roc_auc_smote = auc(fpr_smote, tpr_smote)

fpr_imb, tpr_imb, _ = roc_curve(y_test, y_prob_imbalanced)
roc_auc_imb = auc(fpr_imb, tpr_imb)

# 4. Plotting Kurva
plt.figure(figsize=(8, 6))

# Garis Model SMOTE (Harusnya lebih baik/tinggi)
plt.plot(fpr_smote, tpr_smote, color='green', lw=2,
         label=f'KNN w/ SMOTE (AUC = {roc_auc_smote:.2f})')

# Garis Model Imbalanced (Sebagai pembanding)
plt.plot(fpr_imb, tpr_imb, color='red', lw=2, linestyle=':',
         label=f'KNN Imbalanced (AUC = {roc_auc_imb:.2f})')

# Garis Diagonal (Random)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison: KNN Model')
plt.legend(loc="lower right")
plt.grid(alpha=0.3)

# Simpan dan Tampilkan
plt.savefig('knn_roc_curve_comparison.png', dpi=300)
print("‚úÖ Gambar berhasil disimpan: knn_roc_curve_comparison.png")
plt.show()